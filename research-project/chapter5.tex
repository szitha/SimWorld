\chapter{Conclusion}

The use of machine learning and telescope sensor data has paved a new way for the development of calibration methods. We have used the telescope pointing and environmental sensor data to learn, using the variability of the complex gain calibration solutions G for the calibrator PKS1613-586 as a function of time. We took advantage of the large amount of external data generated by a radio telescope during scientific observations, and such information not being included in the currently used traditional calibration software. The implementation of the ZCal algorithm is based on regression machine learning algorithms with the aim of predicting the calibration solutions and studying each antenna's behaviour. Here we have considered multiple observations and collected the observable quantities such as air temperature, relative humidity, wind speed, wind direction, air pressure and telescope pointings for each track of the calibrator PKS1613-586 in time. With each 1GC calibration solution per observation from CASA, we constructed a matrix of training sample $n_L$ and testing sample $n_T$ to train the machine learning algorithms DT, RF, EXT, and KNN to be able to discern the patterns that relate complex gain  calibration solutions of a specific calibrator to external parameters.       

Since gain solutions are complex, we have implemented  ZCal to learn on phase and amplitude to allow simplicity during the training and to incorporate the differences or variation of amplitude and phase per antenna due to various effects. Each learning algorithm ran on the learning sample $N$ times and its error was estimated on the test sample. We presented a statistical framework to measure the accuracy of each multi-output regression model and our results are encouraging with an rms error of $\approx < 0.5$ during testing of our models using the testing data for gain amplitude and phase. Comparing the performances of these algorithms, the random forest, extremely randomized tree and K-nearest neighbor were shown to be the best for our purpose. We then applied these methods to the validation observation datasets test-1 and test-2, where we obtained bad performance in predicting the amplitude and phase calibration solutions. When comparing the model predicted solutions with CASA, one observes that the models predict the gain amplitude and phase solutions similar to CASA sometimes fails. This can be due to various reasons, i.e, the observations used for training and testing may have distinct properties that our algorithms learned; the dataset used does not give full representation of the problem. From the results obtained, we observed that the environmental and the pointing effects are strongly correlated to the amplitude than phase. 

The results and the analysis of the algorithms  has shown that extremely randomized tree methods work by decreasing variance while at the same time increasing bias thereby producing a small rms error. Once the randomization level is properly adjusted, the variance almost vanishes while bias increases only slightly with respect to standard trees \citep{geurts2006extremely}. The resulting models, random forest, extremely randomized trees and K-nearest neighbor are thus proven to be best in learning complex problems such as calibration. These methods have many advantages over
existing shallow learning approaches, i.e., they can be trained
and used in only seconds and hence provide substantial
speed-ups over other methods; secondly they perform non-linear and non-parametric regression, which means that the method can
use orders of magnitude fewer models for the same level
of precision, while additionally attaining a more rigorous
appraisal of uncertainties for the predicted quantities \citep{bellinger2016fundamental}. However, our method has some limitations which led to models in highly learning the behaviour of the amplitude. This is due to less training data from KAT-7 which limited us from training our models to learn all possible observational space.

In this dissertation, we have introduced a machine learning approach to finding the correlation between sensor data and calibration solutions for radio observations. The results obtained prove that machine learning  methods  and sensor data can be used as a tool for calibration. This proves that one can generate CASA-like solutions using sensor data as a function of time and machine learning with high accuracy.

In this study, we trained the model looking only at time-dependent corrections. However in calibration steps, there is also a process called bandpass calibration, which focuses on correcting for the frequency-dependent effects. These variations in frequency arise as a result of non-uniform filter passbands or other frequency-dependent effects in signal transmission. It is usually the case that these frequency-dependent effects vary on timescales much longer than the time-dependent effects \citep{editioncasa}. The most complete approach to bandpass calibration using CASA is to observe a strong line-free continuum source to find the bandpass characteristics (amplitude and phase) of each antenna-receiver combination \citep{editioncasa}. In future, we intend to study the correlation between the sensor data and the response of the bandpass to improve the performance of our models in predicting highly accurate gain amplitude and phase solutions for calibration. This will also improve ZCal in learning to predict the correct amplitude, as it has learned the sinusoidal variation well. In addition, more sensor data will be included, such as digitiser input and output power, spectrometer and lower noise amplifier sensor data.  









