\chapter{Radio astronomy}

\section{Introduction}


Modern day astronomy is at an unprecedented time with a deluge of data from different telescopes. In contrast
to the conventional methods, today astronomical discoveries are data driven. The upcoming Square Kilometer Array (SKA) is expected to produce terabytes of data every hour \citep{aniyan2017classifying}. With this exponential growth of data, challenges for data calibration, reduction and analysis also increase, making it difficult for astronomers to manually process and analyse the data. Therefore, intelligent and automated systems are required  to overcome these challenges.

One of the main issues in radio astronomy is determining the quality of observational data. Astronomical signals are very weak  by the time they reache the Earthâ€™s surface. They easily get corrupted by  atmospheric interferences, incorrect observational parameters (e.g. telescope locations or telescope pointing parameters), malfunctioning signal receivers, interference from terrestrial man-made radio sources and tracking inaccuracies \citep{taylor1999synthesis}. Therefore it is required to do proper corrections to the observational data before doing science. Radio astronomers spend a considerable amount of time performing a series of preprocessing steps called $\textit{calibration}$ which involves the determination of a set of parameters to correct the received data. These parameters generally include instrumental as well as astronomical parameters. The general strategy for doing these corrections makes use of a calibrator source. Calibrator sources are well suited for determining astronomical parameters for data corrections because they have known characteristics such as the brightness, shape, and frequency spectrum \citep{taylor1999synthesis}. This process of calibration is iterative and time-consuming.

During science observations different  external parameters like atmospheric pressure, temperature  wind conditions, and relative humidity  are also collected through thousands of sensors attached to the telescopes and its adjoining instrumentation. The data coming from different sensors may provide information about the external conditions that may have corrupted the observed data. This piece of information is not always included in the conventional calibration steps. We propose to use machine learning methods to predict the calibration solutions looking at pointing and environmental sensor data. This is mainly motivated by the fact that calibration steps do corrections to data that is corrupted by environmental parameters.

In this project, we make use of the data from the Karoo Array Telescope (KAT-7), an array consisting of $7$ telescopes which is a precursor to the MeerKAT radio telescope. We look at pointing azimuth, elevation, scan, offset, temperature, wind speed, air pressure, relative humidity sensor data recorded during  observations with a calibrator source PKS1613-586 to generate the training and testing dataset. The overall generated dataset contains sensor data per telescope and calibration solutions for correcting the signal received by each telescope in horizontal polarization(h-pol)  and vertical polarization(v-pol). These calibrator solutions are calculated using one of the traditional astronomy software called CASA which is used for data calibration and imaging in radio astronomy.
 
\section{Introduction to radio astronomy}

Radio astronomy is one of the most fascinating fields to study about the Universe. Astronomers capture and analyze the electromagnetic signals emitted by distant objects, such as stars and galaxies using a radio telescope. In Section \ref{Ra} we present a brief introduction in radio astronomy including the interferometry vs single dish in Section \ref{RvI}. In Section \ref{Calibr} we define calibration in radio astronomy and the different techniques used for data calibration in Section \ref{caltech}.
\label{Ra}
\subsection{History}


Radio astronomy is the study of celestial sources emitting radio waves \citep{verschuur2015invisible}. A wave is an oscillatory motion of any kind, the most familiar being waves on the surface of water, sound waves and vibrations of the air or of various material substances. There are also wave disturbances in electric and magnetic field\newtheorem{mydef}{Definition}s. Such waves are responsible for what we experience as, e.g X rays, visible light, or radio waves \citep{cassidy2002wave}. Traditional astronomy is based on observations at optical (i.e. visible) wavelengths, but astronomical sources emit radiation not only as visible light but
also across the electromagnetic spectrum from gamma rays at short wavelength$(\lambda)$ to radio at long wavelength (low frequency) as shown in Figure \ref{images/Electromagnetic-Spectrum.png} \citep{staats2016genetic}.

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.7\textwidth]{images/Electromagnetic-Spectrum.png}
    \caption{The electromagnetic spectrum}
  \label{images/Electromagnetic-Spectrum.png}
\end{figure}

Electromagnetic radiation is a group of waves created by fluctuations of electric and magnetic fields propagating through space at the speed of light ($c=3\times 10^{8} m/s$) carrying electromagnetic radiant energy \citep{staats2016genetic}.\;There are numerous emission mechanisms in the universe that generate radio waves.
Each portion of the electromagnetic spectrum reveals a unique view of the universe and so modern astronomy employs various instruments to look at each portion of the spectrum.\;The Earth's atmosphere absorbs electromagnetic radiation at most infra-red, ultraviolet, X-ray, and gamma-ray wavelengths. This means we can only observe the Universe from the ground in two windows namely the radio and visible wavebands. Radio waves can reveal objects that do not radiate in other parts of the electromagnetic spectrum, and they are able to pass through galactic dust clouds that obscure the view in the optical range and they can penetrate through the Earth's atmosphere (subject to some limits depending on frequency) \citep{thompson2001interferometry}. After received by a radio telescope, the data is amplified and transferred to a computer (include figure) for further  data processing which is discussed in next chapter.


Radio astronomy was discovered accidentally by a radio Engineer, Karl Jansky in the 1930s.
Jansky was assigned the task of investigating sources of radio interference radio-telephone communication system at short wavelengths (10-20 meters) \citep{verschuur2015invisible}.
The purpose of this task was to find out the direction of the radio wave interference so they could easily tune out the interference by using directional antennas pointed away from the direction of the interference. In the process of conducting this task, Jansky constructed an antenna designed to receive radio waves at a frequency of 20.5 MHz (a wavelength of about 14.5 meters) \citep{Jansky0}. The antenna was mounted on a circular train track so that it could be rotated in all possible angles along the ground and be able to detect radio signal in all possible directions. After several months of recording and analysing the radio signals from all directions, Jansky's investigation was successful and he identified two known signals (from local and  distant thunderstorms) which were interfering with the radio-telecommunication system, and one unknown signal (faint steady hiss). Jansky continued to investigate the unknown signal for over a year and eventually figured out that the radiation was coming from the Milky Way. The signal was the strongest in the direction of the center of our Milky Way
galaxy, in the constellation of Sagittarius. This was the first detection of non-black body radiation at radio wavelengths from an extraterrestrial source. Black body radiation is the radiation given off by any object
related to its temperature \citep{Jansky1}.

After Jansky's project at Bell laboratory ended, Bell was not interested in studying astronomy any more. In 1937, an astronomer Grote Reber who was fascinated by Jansky's ground breaking discovery decided to continue where Jansky left off by further investigating the cosmic radio waves from the Milky Way Galaxy. To pursue this research, Grote built the first single dish radio telescope with a receiver strong enough to detect cosmic radio signals at the back of his yard. He spent hours at night scanning the sky at different frequencies. He was finally successful at detecting radio emission from the Milky Way Galaxy confirming Jansky's discovery \citep{verschuur2015invisible}.   

Astronomical signals tend to be weak by the time it reach the ground. The need for greater sensitivity and higher resolution has resulted to the in the creation of telescopes that have larger collecting area for more radio energy to be focused on the receiver \citep{verschuur2015invisible}. However constructing a single dish telescope larger enough i.e. $>500m$ to achieve high angular resolution $\theta \approx\frac{\lambda}{D}$ (where $\lambda$ is the wavelength of the electromagnetic radiation observed and $D$ is the aperture diameter of the radio telescope), is physically impossible due to the cost of the materials and structure being at high risk to collapse during high wind conditions. The angular resolution of a radio telescope measures its ability to detect fine details in the structure of the observed celestial source. For example, to obtain an angular resolution of 1 arc-second, would require a single dish radio telescope diameter to be appropriately thousands of metres \citep{verschuur2015invisible}. 

\section{Single dish vs Interferometry}
\label{RvI}


A single dish survey can be complemented by an array of small radio telescopes providing higher sensitivity and higher resolution images  \citep{wright2004single}. This technique is called radio interferometry. The radio interferometry is mostly used for to obtain high resolution images of astronomical sources, while as a single dish technique is mostly considered as a tool for low spacial resolution, i.e, they allow for imaging of very large sources \citep{stanimirovic2002short}. Though these two techniques are quite different, they both provide measurements of the Fourier transform of  some region in the sky \citep{cornwell1988radio}. In this thesis we focus on the interferometer which consist of two or more sub-apertures grouped together to form a large array \citep{verschuur2015invisible} as shown in Figure \ref{images/Rint.png}. Though the telescopes are placed at different positions separated by the distance $b$, the resulting power output from all the telescopes is combined. For an interferometric array, the angular resolution is defined as  $\theta \approx\frac{\lambda}{B}$, where $B$ represents the t maximum baseline in the array. 

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.45\textwidth]{images/Rint.png}
    \caption{Two antenna interferometer diagram [National Radio Astronomy Observatory]}
  \label{images/Rint.png}
\end{figure}

The Figure \ref{images/Rint.png} is illustrating a simple two two-element interferometer consisting of baseline $\overrightarrow{b}$ (we will refer to the left antenna as antenna 1 and the right antenna as antenna 2). This can be extended to multi-antenna arrays by adding more $N$ antennas in the array such that the number of baselines  $\frac{N(N-1)}{2}$  increases \citep{zensus1995very}. From Figure \ref{images/Rint.png}, suppose a distant star is in the direction $\widehat{s}$ observed, the incoming signal will arrive in each radio telescope slightly at different times. Now to compensate this time difference such that the signal arrives in each telescope at the same time, a time delay term $\tau_{g}=\frac{\overrightarrow{b}\cdot\widehat{s}}{c}$ is introduced to produce voltages $V_1$ and $V_2$ from antenna 1 and antenna 2 denoted by: 

\begin{equation}\label{eq111}
\begin{split}
V_1(t)&=V\cos[\omega(t-\tau_{g})], \text{where} \nu=\frac{\omega}{2\pi}\; \text{is the center frequency} \\
V_2(t)&=V\cos(\omega\tau_{g})
\end{split}
\end{equation}

$V_1$ and $V_2$ are then  multiplied and time averaged by the correlator to yield an output response whose amplitude $R$ is proportional to the point-source flux density and whose phase depends on the time delay and the frequency.

\begin{align}
V_1 \times V_2 = V^2 \cos(\omega\tau_{g})\times \cos[\omega(t-\tau_{g})]
\end{align}
From $\cos A\cos B= \frac{1}{2} \left(\cos (A+B) + \cos (A-B) \right)$, 
we therefore have 
\begin{align*}
V_1 \times V_2&= \frac{V^2}{2} \left( \cos(\omega\tau_{g} + \omega t-\omega \tau_{g} )\right)\\
&= \frac{V^2}{2} \left(\cos(2\omega t - \omega \tau_{g}) + \cos (\omega\tau_{g})\right)
\end{align*}

We then take the time average to remove the high frequency term $\cos(2\omega t - \omega \tau_{g})$, such that we obtain the output 
\begin{align}
R&= <V_1V_2> = \frac{V^2}{2}  \cos (\omega\tau_{g})\\
  &= \frac{V^2}{2}  \cos \left( \frac{\omega}{c} \overrightarrow{b} \cdot \widehat{s} \right)\\
   &= \frac{V^2}{2}  \cos \left( \frac{2\pi \nu}{c} \times
   \overrightarrow{b} \cdot \widehat{s} \right). 
\end{align}

The amplitudes $V1$ and $V2$ are proportional to the electric field produced by the  source multiplied by the the voltage gains of antennas 1 and 2. Thus the output amplitude $\frac{V^2}{2}$ is proportional to the point-source flux density $S$ multiplied by $\sqrt{(A_1, A_2)}$, where $A_1$ and $A_2$ are the effective collecting areas of the two antennas \citep{NRAO}.

From equation \ref{eq111} 
Radio interferometry has enabled astronomers to make measurements of fine angular  details including parameters such as intensity, polarization and frequency spectrum \citep{thompson2001interferometry}.

\section{Calibration in radio astronomy}
\label{Calibr}
\subsection{Interferometry Visibility}
In an interferometric array, the measured visibilities  which are the 2-dimensional Fourier transform of the sky's intensity at different baseline coordinates, are defined by
\begin{align}
V(u,v)\approx \mathcal{F}\left\{I\right\}(u,v)=\int \int A(l,m) I (l,m)e^{-2\pi i(ul+vm)} dl dm,
\label{Vis}
\end{align}
where $(u,v)$ denotes the projected baseline coordinates in the 2D Fourier transform plane  measured in wavelength along the axes in the east-west and north south direction, and changes with time as the earth rotates  \citep{taylor1999synthesis}. The orthogonal coordinates $(l, m)$ represent the position of a source or the phase reference position. In the 2D analysis $l$ and $m$ are defined as the cosines of the  angles between the direction $(l,m)$ and $(u, v)$. $I(l,m)$ is the intensity distribution of a source and its Fourier transform  ${F}\left\{I\right\}$ represents the amplitude and phase of a sinusoidal component of the intensity profile with spatial frequency $u$ and $v$; $A(l, m)$ represents the effective collecting area of the antennas with respect to the direction of the incoming radiation \citep{thompson2001interferometry}.

For simplicity of equation \ref{Vis}, the term $A(l,m)$ is most often assumed to be 1 such that the Van Cittert Zernike theorem states, \citep{thompson2017interferometry}
\begin{align}
V(u,v)\approx \mathcal{F}\left\{I\right\}(u,v)=\int \int I (l,m)e^{-2\pi i(ul+vm)} dl dm.
\label{V}
\end{align}
The measured visibilities $V(u,v)$ and the sky brightness  $I(l,m)$ are Fourier pairs $V(u,v) \rightleftharpoons I(l,m)$, where $\rightleftharpoons$ is the Fourier transformation. The sky
brightness can readily be recovered from the measured visibilities by an inverse Fourier transform such that we have, 
\begin{align}
I^{True}(l,m)\approx \mathcal{F}^{-1}\left\{V\right\}(l,m)=\int \int V (u,v)e^{-2\pi i(ul+vm)} du dv .
\end{align}
Since for every sky's brightness $I$ $\exists$ visibility function $V(u,v)$, the array of antennas with baselines $b=(u_i,v_i)$  measures only certain values in the set of continuous  $(u,v)$ coordinates in the visibility function $V(u,v)$. This measured set of values is called the \emph{Sampling function} denoted by \citep{taylor1999synthesis}, \[ S(u,v) =
  \begin{cases}
    1   & \quad    \text{at uv point}\\
    0  & \quad  \text{ otherwise}\\
  \end{cases}
\], $\forall$ baselines. The actual data provided by the array is called  sampled visibilities denoted by  $S(u,v)\times V(u,v)$. The Fourier transform of these sampled visibilities is the dirty Image,
\begin{align}
I^{D}(l,m)=\int \int S(u,v)\times V(u,v) e^{-2\pi i(ul+vm)} du dv.
\label{Samp}
\end{align} 
Using the $\textit{convolution theorem}$ for Fourier transforms which states that the Fourier transform of the convolution of two functions is the product of their Fourier transforms denoted by 
\begin{align}
f*g\rightleftharpoons \mathcal{F} \mathcal{G},
\end{align}
where $f\rightleftharpoons \mathcal{F}$ and $g\rightleftharpoons \mathcal{G}$.
From equation \ref{Samp}, we therefore have 
\begin{align}
I^{D}=PSF \circ I^{True},
\end{align}
where 
\begin{align}
PSF(l,m) = \int \int S(u,v)e^{-2\pi i(ul+vm)} du dv,
\end{align}
represents a point spread function  corresponding to the sampling function $S(u,v)$ \citep{taylor1999synthesis}.


\subsection{Calibration}
\label{Calib}
In radio astronomy, ideally one might think that after obtaining the observed visibilities the next step would be to directly retrieve the actual visibilities of the target source and perform imaging. However, in reality it is not as simple as shown by equation \ref{V}. The measured visibilities $V^{obs}$ are different from the actual visibilities $V^{True}$, not only due to the instrument being discrete as shown in equation \ref{Samp}, but most importantly due to instrumental and environmental effects \citep{abebe2015study}. An example of these effects on the signal measured by a radio interferometry include antenna gains (slowly and fast time-varying instrumental part), atmospheric effects, pointing errors (tracking inaccuracies) and incorrect observation parameters (antenna pointing parameters). Signal effects are classified in two types; direction independent effects (affects signal from all direction of the sky) and direction dependent effects (which vary based on the sky position of the signal) \citep{taylor1999synthesis}. These effects can be corrected by estimating the errors associated with the measured visibilities, thereby recovering the true visibilities. This process is called calibration. In its simplest form, calibration minimizes the difference between observed and predicted (model) visibilities by estimating the complex instrumental gain response \citep{grobler2016calibration}. 

Suppose for baseline pair $(i,j)$, the observed visibility is $V^{obs}_{i,j}(t)$ and the true visibility is $V^{True}_{i,j}(t)$ at observation time $t$. The basic calibration formula is written as,

\begin{align}
V_{i,j}^{obs}=G_{i,j} V_{i,j}^{true} + \epsilon_{i,j}(t) ,
\end{align}
where $G_{i,j}(t)$ denotes the complex antenna gains for baseline $(i,j)$ as a results of unwanted effects and may vary with time \citep{thompson2001interferometry}. The extra term $ \epsilon_{i,j}(t)$ is a stochastic complex noise \citep{taylor1999synthesis}.

Most of the corruptions in data occur before the signal gets correlated and the response associated with antenna  $i$  does not depend on the response of antenna $j$. The baseline-based complex gain $G_{i,j}$ can therefore be approximated by the product of amplitude $A$ and phase $\phi$ such that we have,  

\begin{align}
G_{i,j}(t)= g_i(t)g^*_j(t) = A_{i}(t)A_{j}(t) e ^{i\left(\phi_i(t)-\phi_j(t)\right)},
\label{Sols}
\end{align}

where  $A_{i}(t)$, $A_{j}(t)$ are antenna-based amplitude solutions and $\phi_i(t),\phi_j(t)$ are antenna-based phase solutions. Calibration means to find the appropriate $A$ and $\phi$ for the corrupted visibilities. One standard technique for measuring the gain calibration solutions is to obtain dedicated calibration observations of a part of the sky that contains a single known, relatively strong point source. This is to measure the instrumental phase since the telescopes on the ground can only measure the phase differences rather than measuring absolute phase reference. Therefore, the reference for phase visibilities can be practically accomplished by observing point-like calibrator sources. Using these sources, one can determine the phase deviation from the desired reference point. Periodic observation of these sources is very important  to track the phase and gain changes in an array. Above all, they have the paramount advantage of estimating time dependent phase changes incurred by the atmosphere \citep{taylor1999synthesis}.

The selection of a good calibrator source in the sky is based on the following desirable characteristics \citep{thompson2001interferometry}, 

\begin{enumerate}
\item They should have known positions in the sky, i.e the calibrator should be close to the target source. 
\item  Their flux densities have to be strong enough so as to get suitable signal-to-noise ratio (SNR) in a short time.
 \item The calibrator should be a point source (unresolved) if possible. 
 \item Their spectral properties should be known.
 \end{enumerate}
 
 Note that the source that is the subject of astronomical investigation will be referred to as "target sources" to distinguish them from the calibrator sources \citep{thompson2001interferometry}.
 
Suppose a target source is observed with measured visibility $V(u,v)^{obs}$, to calibrate the antenna-based complex gain factor $G_{i,j}(t)$ as a function of time and antenna pair $(i,j)$, a point source calibrator is observed for which the measured visibility is, 
\begin{align}
V(u,v)_{calibrator}&= G_{i,j}(t) S_{calibrator}\\
G_{i,j}(t)&= \frac{V(u,v)_{calibrator}}{S_{calibrator}}
\end{align}
\citep{thompson2001interferometry}
where S indicates the flux density of the calibrator. Now to calibrate the visibilities of the target source we can write, 
\begin{align}
V(u,v)^{true}&= \frac{V(u,v)^{obs}}{G_{i,j}(t)}\\
&= V(u,v)^{obs} \times \frac{S_{calibrator}}{V(u,v)_{calibrator}} 
\end{align}
\citep{thompson2001interferometry} 

\section{Calibration techniques}
\label{caltech}
With the improvement and complexities of the new radio astronomy instruments, various calibration techniques have been developed to overcome these challenges  posed by the new instruments thereby producing accurate calibration results. These techniques are classified into first generation calibration (1GC), second generation calibration (2GC) and third generation calibration (3GC). In this thesis our focus will be on 1GC using the Common Astronomy Software Applications a (CASA) which is a suite of functions for the reduction and analysis of radio astronomical data with IPython interface, and is currently maintained by the National Radio Astronomy Observatory \citep{mcmullin2007casa}. 

\subsection{First generation calibration (1GC)}

This is the first step in the data reduction process where the received signal in each baseline is compared to the signal from a known source (the calibrator sources) to address the following errors in the response of the instrument. 

\begin{itemize}

\item Bandpass calibration $B$ is used to solve for gain variations
in frequency. Variation in frequency arises as a result of non-uniform filter passbands or other frequency dependent effects in signal transmission. It is usually the case that these frequency-dependent effects vary on timescales much longer than the time-dependent effects. The CASA task which solves these frequency dependant complex gains is called $\textit{bandpass}$. This is done by observing a strong calibrator source with known model visibilities and spectrum characteristics for sufficient time to reach the required accuracy \citep{taylor1999synthesis}.

\item Delay calibration $K$ is used to correct for the phase delay errors. The arriving signal does not propagate to all the antennas at the same time. Delay calibration equalizes these propagation differences on individual signal paths at the input of the correlator and removes the largest phase difference across the observing band \citep{taylor1999synthesis}.   

\item Gain calibration $G$ is used to solve for time dependant complex gain variation. These gain variations include the relative amplitude and phase gain for each antenna, phase and amplitude drifts in the electronics of each antenna, amplitude response as a function of elevation (gain curve), and tropospheric amplitude and phase effects. Some of these calibrations are known beforehand $("a priori")$ and others must be determined from observations of calibrator sources. The CASA task used to solves for these antenna-based gains in each polarization in specified time solution intervals  is $\textit{gaincal}$ \citep{editioncasa}.  

Note that it is not always possible to find a calibrator source that satisfies the requirements mentioned in section \ref{Calib}, especially point number 2. In such cases it may be necessary to find a calibrator source that is a point source  close to the target source and then calibrate it against one of the more commonly used flux density reference calibrators such as PKS1934-638, 3C147 or 3C286 \citep{thompson2001interferometry}. 

\item Flux calibration is used to calibrate the flux density of source calibrators with unknown flux densities. The flux density of the unknown calibrators is assumed to be $1Jy$. This assumption is done such that the complex gain solutions G of the reference flux density calibrator and one with unknown flux density are compared and scaled so that they match as much as possible. The CASA task used to perform this scaling or bootstrapping is $\textit{fluxscale}$ \citep{editioncasa}.
\end{itemize}

The solutions obtained from the tasks $(\textit{gaincal}, \textit{bandpass}, \textit{fluxscale})$ are saved in tables and then applied on uncalibrated data 
to form calibrated data.

\subsection{Second generation calibration (2GC)}

Once the calibrated data is obtained by performing the first generation calibration, the first model image is computed. A process called $\textit{self calibration}$ can be performed to obtain more accurate images by making additional corrections to the antenna gains as a function of time. It is very similar to the basic calibration. The main difference is that the model of the source is generally more complex than assuming it it is a point source at the phase centre and also the observed field is used to calibrate itself \citep{wieringa1992investigation}. The self-calibration technique finds antenna gains $g_i$, which minimise the difference between the measured visibilities $V_{i,j}$, and the model visibilities $\hat{V}_{i,j}$ \citep{grobler2016calibration}, 

\begin{align}
\epsilon^2 = \sum |V_{i,j}-g_i g_j^* V^{obs}_{i,j}|^2
\label{ls}
\end{align}

Self calibration can be briefly described using the flowchart in Figure \ref{self},
\begin{figure}[H]
  \centering
    \includegraphics[width=0.7\textwidth]{images/Selfcal.png}
    \caption{Selfcal flow diagram} 
    \label{self} 
\end{figure}

and can be performed using the following method:
\begin{enumerate}
\item Create an initial source model from an initial image (1GC).
\item Set your model to the initial skymodel and use it to find antenna gains using the least squares fit as shown in equation \ref{ls}.
\item Apply gains to the observed visibilities.
\item Image the corrected visibilities and create new model visibilities. 
\item Return to Step 2 with your new skymodel or terminate if the current model is satisfactory.
\end{enumerate}
\subsection{Third generation calibration(3GC)}

The first and second generation calibration discussed in the previous sections focused mainly on solving direction independent effects. With the wide field of views of current and future generation radio telescopes such as the Extended Very Large Array, Low Frequency Array and the SKA, direction dependent effects poses a challenge in calibration which result the third generation calibration (3GC). These are effects that vary not only with time and frequency but also the viewing direction \citep{pandey2009calibrating}. This include variations in the primary beam or the sensitivity pattern of each antenna. 