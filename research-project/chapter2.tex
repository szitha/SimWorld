
\chapter{Machine learning}
Machine learning is programming computers to optimize a performance
criterion using example data or past experience. In this chapter we present machine learning applications to challenges posed by big data. In Section \ref{BigD}, we give a brief definition of big data  and the challenges currently faced in radio astronomy. In Section \ref{Intro} we give a brief introduction and examples of machine learning,  and in Section \ref{Process}, \ref{comp} we  present the process of machine learning and model complexity.
\section{Big data}
\label{BigD}
\begin{figure}[H]
  \centering
    \includegraphics[width=0.5\textwidth]{images/Expgrowth.png}
    \caption{The exponential growth of data from gigabytes to zettabytes [Amazon].}
  \label{datagrowth.png}
\end{figure}

In the past few decades, computing power has been rising exponentially, 
and as a related consequence, the enormous quantities and complexity of the observed data, primarily in digital form. Such data are referred to as $\textit{big data}$ and traditional data-processing tools are inadequate to deal with them. In addition to the natural world, big data are now creating a digital world, in which extracting new and useful information from the data already taken and stored is becoming a major endeavor in itself \citep{ball2010data}. This action of knowledge discovery in databases is commonly referred to as \textit{data mining} \citep{ball2010data}. In data mining, a large volume
of data is processed to construct a simple model with valuable use, e.g., having high predictive accuracy  \citep{alpaydin2014introduction}.



\section{An Introduction to machine learning}
\label{Intro}

For a computer to solve a problem, one need an algorithm. An algorithm
is a sequence of instructions carried out to transform
the input to output. e.g, one can design an algorithm for
sorting, where the input is a set of alphabets and the output is an ordered
list from A to Z. For the same task, there may be various algorithms and one may be
interested in finding the most optimum one, requiring the lowest number of
instructions and memory to run. For some tasks, however, one does not have an algorithm, for example to differentiate between legitimate emails and spam emails \citep{alpaydin2014introduction}. Therefore what we lack in knowledge, we make up for in the collected data. One can easily compile thousands of example messages, some of which one knows to be spam and then we get to learn what characterizes a spam email \citep{alpaydin2014introduction}. 

Learning is what gives humans flexibility, the fact that humans can adjust and adapt to new circumstances and learn new
tricks no matter at any age \citep{marsland2015machine}. The important parts of human or animal learning are adapting, remembering and generalising. Being able to recognize old events, and to know which actions are to be taken, and also knowing how to distinguish between different situations is what makes learning useful \citep{marsland2015machine}. 

 Machine learning is not only a database problem, but is also part
of artificial intelligence. For a system to be intelligent, it needs to have the ability to learn and adapt in any changing environment. If the system can learn and
adapt to changes, then it can easily predict future solutions not provided by the system designer \citep{alpaydin2014introduction}. This involves tasks such as  recognition, prediction, diagnosis, robot control,  
planning etc \citep{nilsson1996introduction}.
Machine learning also helps one find solutions to many problems in robotics, speech recognition and vision. Machine learning is is generally based on programming computers to optimize their performance criterion by using example data that consist of various events. A model is defined
up to some parameters, and part of the learning process is to execute a computer program
to find the optimum parameters of the model using the training data that is based on past experience with different events \citep{alpaydin2014introduction}. The model may be descriptive to gain knowledge from data or predictive to make predictions in the
future.
Machine learning uses the theory of statistics in building mathematical
models, because the core task is making inference from different samples \citep{alpaydin2014introduction}.


Given a class of tasks T, an experience E and measure of performance P, a computer program is said to learn from E with respect to T if the measure P at T improves for more observations E provided \citep{michalski2013machine}. 
\subsection{Examples of machine learning}

We are surrounded by machine learning-based technology such as online shopping where  search engines learn how to bring us the best results and a list of the most relevant products related to our search, email (spam filters, smart email categorization, etc)  where anti-spam software learns to filter our email messages into spam or not-spam using simple rule filters. A similar approach is used by Gmail to categorize our emails into primary, social, and promotion inboxes, as well as labelling emails as important. 

In a research paper, "The Learning Behind Gmail Priority Inbox" \citep{aberdeen2010learning}, Google outlines its machine learning approach  and notes: " When a user marks messages in a consistent direction, we perform a real-time increment to their threshold." Every time the user marks an email as important, Gmail learns. The researchers tested the effectiveness of Priority Inbox on Google employees and found that those with Priority Inbox "spent 6\% less time reading email overall, and 13\% less time reading unimportant email.". Social networking, i.e. Facebook  automatically highlights faces and suggests friends to tag when uploading a photo. A similar approach is used on digital cameras to learn how to detect faces.Smartphones today are equipped with a standard feature to convert voice to text; by pressing a button or saying a particular phrase ("OK Google", for example), you can start speaking and your phone converts the audio into text and recognizes voice commands \citep{Techemergence}.  
Machine learning is also widely used in scientific applications such as astronomy and health.


One common feature of all of these applications is that, in contrast to more
traditional uses of computers, in these cases, owing to the complexity of the patterns that need to be detected, a human programmer will find it difficult to provide finely detailed specification of how to tackle such tasks\citep{shalev2014understanding}.  In recent years, the world's technology has become increased consistently, as shown in Figure \ref
{datagrowth.png}, and this escalation has led to the amount of data available for learning increasing dramatically. We therefore provide several reasons why machine learning is important, given the data challenges.
\begin{itemize}

\item Machine learning methods can often be used to extract the important relationships and correlations of hidden information among big data.

\item The amount of information available about certain tasks might be too large and complex for humans to encode, whereas machines can learn this knowledge accurately and be able to capture more of it than humans would \citep{nilsson1996introduction}.
\end{itemize} 

Our focus will be based mainly on tasks that are beyond human capabilities. These are families of tasks that are related to the analysis of complex large datasets such as astronomical data. With more available stored digital data, it becomes obvious that there is meaningful information buried in the data that is complex for humans
to make sense of. Learning to detect meaningful information in large
 datasets is a promising domain in which the combination
of programs that learn with computers that have high processing power  opens up new horizons \citep{shalev2014understanding}.

\subsection{Types of machine learning}

\begin{figure}[H]
  \centering
    \includegraphics[width=0.7\textwidth]{images/Ml_techs.png}
    \caption{Machine learning techniques include both supervised and unsupervised learning \citep{Machinelearning}.}
  \label{sup-unsup}
\end{figure}

Machine learning algorithms are broadly divided into unsupervised and supervised methods, also known as descriptive and predictive. In supervised learning, the goal is to predict the value of an output measure based on a number of input measures, i.e, finding the relationship between the input and output based on the training dataset. In contrast to supervised learning, unsupervised learning occurs in the sense that the data can speak for themselves
without preconceptions such as expected classes being imposed \citep{ball2010data}. 

\subsubsection{Supervised learning}
The aim of supervised machine learning is to build a model
that makes predictions based on some evidence in the presence. Suppose  one wants to fit a model $\textbf{Y}=f(\textbf{X})+\epsilon$ with errors $\epsilon$ being additive. Supervised learning attempts to learn the function $f$ by examples given through a teacher, given the training set with input and output observations $T=(x_i,y_i ), i=1,\dots N$. The observed input values $x_i$ are fed into a learning algorithm, which produces outputs $\widehat{f}(x_i)$ in response to the given inputs. The learning algorithm has the property that it can modify its input/output relationship $\widehat{f}$ in response to the computed error $y_i- \widehat{f} (x_i)$ between the original and predicted outputs. This process is known as learning by example. Upon completion of the learning process the hope is that the predicted and real outputs will be close enough with an error of approximately zero \citep{friedman2001elements}.

Supervised learning uses regression and classification techniques
to develop predictive models. Depending on the given dataset, variables can be characterized as either qualitative (also known as categorical) or quantitative. Quantitative variables takes on numerical values. Examples include a person's height, age, air temperature, wind speed, etc. Whereas, qualitative variables take on input vectors and decide which of N classes
they belong to as shown in Figure \ref{RC}, based on training from exemplars of each class or category. Examples of qualitative variables include a person’s gender (male or female) or whether a person defaults on a debt (yes or no) \citep{aitkin2009statistical}. Qualitative variables are typically represented numerically by codes. The easiest case is when there are only two classes or categories, such as "success"
or "failure", "survived" or "died". These are often represented by a single binary digit or bit as 0 or 1, or else by -1 and 1. For reasons that will become apparent, such numeric codes are sometimes referred to as targets \citep{friedman2001elements}. In machine learning, if the label is numerical, the task is called regression and the learner is also called a fitted regression model, while if the label is categorical, the technique is called classification and the learner is also called a classifier. For both techniques, the training process is conducted on data sets containing label information or examples \citep{zhou2012ensemble}.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.7\textwidth]{images/RC.png}
    \caption{Example of classification and regression \citep{rossant2018ipython}.}
  \label{RC}
  
\end{figure}
Classification tasks are mostly known to be discrete, i.e. each example belongs to only one class, and the set of classes covers the whole possible output space; whereas regression tasks are known to be continuous \citep{stephen2009machine}. However there are some overlaps between the algorithms for these tasks. A classification algorithm may predict a continuous value, but the continuous value is in the form of a probability for a class label and a regression algorithm may predict a discrete value, but the discrete value is in the form of an integer quantity. Some algorithms can be used for both classification and regression with small modifications, such as decision trees and artificial neural networks \citep{brownlee2013prepare}.  

\subsubsection{Unsupervised learning}

In contrast to labelled data,  data items without associated labels can often be obtained in great quantities without much effort to be done on it. The unsupervised learning technique aims at making use of the information provided by the unlabelled patterns to generate appropriate models. 

As illustrated in Figure \ref{sup-unsup}, in unsupervised learning one has only a set observations $T=x_1,x_2,\dots, x_N$. In unsupervised learning one is not interested in prediction, because one does not have an associated output response variable $y_1,y_2,\dots, y_N$. Rather the goal in unsupervised learning algorithms is to discover interesting information about the measurements on the training set $T$. One looks for an informative way to visualize the data and interesting patterns among the observations \citep{james2013introduction}. 

\begin{figure}[H]
  \centering
    \includegraphics[width=0.35\textwidth]{images/cluster.png}
    \caption{An example of clustering method which reveals hidden patterns in data \citep{Machinelearning}.}
  \label{datagrowth.png}
\end{figure}

Clustering is one of the most commonly used unsupervised methods that divide the data into clusters. The number of clusters must initially be specified with a value K. The algorithm uses a distance
criterion for cluster membership, such as computing the Euclidean distance between the clustered points, and a stopping criterion for iteration\citep{ball2010data}.

\section{Process of machine learning}
\label{Process}
\subsection{Data preparation}
Machine learning algorithms learn from data, therefore it is critical that one feed them the right data for the specific problem one want to solve. In this section we will describe the processing steps required for getting data ready for a machine learning algorithm.

Three steps are commonly used in machine learning to process the data, namely data selection, data preprocessing  and data transformation. Data selection has to do with the selection of the the subsets of all available data that one need to address the question or problem on which we are working. Usually assumptions will be made  about the data and be tested at a later stage. After selecting the data, comes the preprocessing step where one decide how to use the data. Firstly, suitable formatting of the data is considered, which could be .csv file format or Numpy file format. In such cases there may be data instances that are incomplete or do not contain useful information. Such cases, the removal or fixing of such data is required. When generating the training dataset, it is crucial  to also consider the computational cost and memory requirement. Sampling the data by taking a smaller representative sample of the selected data may be much faster for exploring the data space and prototyping solutions before considering the whole dataset. The final step is to transform data using scaling, where the preprocessed data may contain attributes with a mixture of scales for various quantities, which then are scaled to range between 0 and 1. This helps to stop the weights from getting too large unnecessarily \citep{marsland2015machine}. One could also use decompositions, which involve attributes that represent a complex concept that may be more useful to a machine learning method when split into the constituent parts, and  aggregations where attributes can be aggregated into a single attribute that would be more meaningful to the problem being solved \citep{brownlee2013prepare}. The most commonly used scaling methods are referred to as data normalisation, or standardisation \citep{marsland2015machine}.
    
\subsection{Feature engineering}

In machine learning applications, whether classification or regression, observation
dataset that one believes to contain information are taken as inputs and fed
to the model for decision-making. Some of the goals in these learning algorithms are: improving the prediction performance of the model and reducing the model complexity. This could help reduce the estimation error and thus prevent overfitting. If one assumes that the observation dataset $\textbf{X}=\mathbb{R}^d$ \citep{shalev2014understanding}, then the complexity of the model would depend on the number of
input dimensions, $d$, as well as the sample size $N$. 
For reduced memory and computation, one is interested in reducing
the dimensionality of the problem such that one has a new feature space $\mathbb{R}^k$ of dimension $k \ll d $. Decreasing $d$ will also decreases the complexity of the algorithm and increase the learning process speed. The
complexity is often broken into two parts: the complexity of training the algorithm, and the complexity of applying the trained algorithm to new data. Training does not happen very often, and is not usually time-critical. However, we often want a decision about a test point quickly, and there are potentially many test points when an algorithm is in use, so this needs to have low computational cost \citep{marsland2015machine}.

When data can be explained with fewer features, one gets a better idea about the process that underlies the data and this allows knowledge extraction. There are two main methods for reducing dimensionality: feature selection and feature extraction. In feature selection, one is interested in
finding $k$ of the $d$ dimensions that give the most information such that the other $(d - k)$ dimensions are discarded. In feature extraction, one is interested in finding a new set of $k$ dimensions that are combinations of the original $d$ dimensions \citep{alpaydin2014introduction}.
 
During algorithm learning, a feature $x_i\in\mathbb{R}$ becomes relevant to a target concept $t$ (what is being learned) if  a pair of examples A and B in the instance space such that A and B exists differ only in their assignment to  $x_i$ \citep{blum1997selection}. This implies that adjusting the value of $x_i$  will affect the desired output of the learning algorithm. Hence it is important to identify the features that are more important for the problem. This invariably requires prior knowledge of the problem and the data. This process is called feature selection.

In any machine learning, algorithm technique selection is mostly driven by the structure of the dataset and type of problem one wishes to solve (regression or classification). Therefore it is important to have better understanding of the dataset and which features are useful prior to the selection and splitting of the dataset, as described in the previous paragraph. The output of the problem is real number, one therefore categorize the problem as regression. The identified algorithms that are applicable and practical to implement are multi-output regression algorithms to be discussed in more details in the next chapter. 


\section{Tuning model complexity}
\label{comp}
In prediction models, prediction errors can be decomposed into error due to variance and error due to bias of the model. There is a tradeoff between a model's ability to minimize the bias and variance during training \citep{fortmann2012understanding}. 
\subsection{Bias and variance }
Understanding these two types of error can help us diagnose model results and avoid the mistake of over and underfitting. Understanding the bias and variance will help one to improve the data fitting process, resulting in accurate models \citep{fortmann2012understanding}.
Error due to bias is the difference between the average prediction of  models and the true value which one is trying to predict. For example, assuming one has multi-models built from a dataset generated randomly, this will result in the models yielding multi-predictions, hence the bias measures how far off in general these model's predictions are from the true value. Error due to variance is the variability of a model prediction for a given data point \citep{fortmann2012understanding}. 

\begin{figure}[H]
  \centering
    \includegraphics[width=0.48\textwidth]{images/Bias.png}
    \caption{Graphical illustration of bias and variance. The center of each target represents a model that perfectly predicts the true value and as one moves away from the centre, the model gets worse at predicting the true value. Variability in the training dataset due to outliers or non-standard values will also result in poor prediction \citep{fortmann2012understanding}.}
  \label{RC}
 \end{figure}
 
Suppose  one has a training set $\textbf{X}=\{x_1,\dots x_n\}$ and and a function $\textbf{Y}=f(\textbf{X})+\epsilon$ with $\epsilon$ being an error term normally distributed with zero mean and variance $\sigma^2$. One wants to find a function $\widehat{f}(\textbf{X})$  that estimates $f(\textbf{X})$ as well as possible using some learning algorithm technique. In this case, one measures the mean squared prediction error at a point $x$ as :
\begin{align*}
Err(x)&= \mathbb{E}\left[(\textbf{Y}- \widehat{f}(x) ) \right]\\
&= \mathbb{E}\left[ \textbf{Y}^2 +\widehat{f}(\textbf{x})^2 -2\textbf{Y}\widehat{f}(x)\right]\\
&= \mathbb{E}\left[\textbf{Y}^2 \right] + \mathbb{E}\left[\widehat{f}(x)^2 \right]- 2\mathbb{E}\left[\textbf{Y}\widehat{f}(x)\right]
\end{align*}
Since $\text{Var}(\textbf{Y}) = \mathbb{E}\left[\textbf{Y}^2 \right]- \mathbb{E}\left[\textbf{Y}\right]^2$, then we have  $\mathbb{E}\left[\textbf{Y}^2 \right] =\text{Var}(\textbf{Y}) + \mathbb{E}\left[\textbf{Y}\right]^2$, such that
\begin{align*}
Err(x)&= \text{Var}(\textbf{Y}) + \mathbb{E}\left[\textbf{Y}\right]^2 + \text{Var}\left[\widehat{f}(x)\right] + \mathbb{E}\left[\widehat{f}(x) \right]^2- 2f\mathbb{E}\left[\widehat{f}(x) \right]\\
&= \text{Var}(\textbf{Y}) + \text{Var}(\widehat{f}) + (f(x)- \mathbb{E}\left[
\widehat{f}\right]^2)\\
&= \sigma^2 + \text{Var}(\widehat{f})+ \text{Bias}\left[\widehat{f}\right]^2
\end{align*}

where $\sigma^2$ represents the irreducible error \citep{fortmann2012understanding}. 

There are various ways of managing the bias and variance during training, one of them being resampling and bootstrap aggregating. These techniques can be used to reduce the variance in model prediction. In bootstrap aggregating, replicates of the original dataset are created using a random selection with replacement. Each randomly selected data set is then used to construct a new model and the models are combined together into an ensemble. To make a prediction, all the models in the ensemble are averaged \citep{fortmann2012understanding}.

\subsection{Overfitting and underfitting}

\begin{figure}[H]
  \centering
    \includegraphics[width=0.7\textwidth]{images/biasvariance.png}
    \caption{The figure is showing the bias and variance contribution to total error. Dealing with bias and variance is about dealing with overfitting and underfitting of the model. The bias is reduced and the variance is increased in relation to the model complexity. As the parameter space of the model increase, the more one experience  complexity whereby the variance increases and becomes the primary concern while bias steadily decreases \citep{fortmann2012understanding}.}  
\end{figure}

Understanding bias and variance is critical for understanding the behaviour of prediction models, but in general what one really cares about is the overall error, not the specific decomposition. The optimum point for any model is the level of complexity at which the increase in bias is equivalent to the reduction in variance as shown in the figure above. If model complexity exceeds this optimum point; we are in effect overfitting our model; while if our complexity falls short of the optimum point, we are underfitting the model \citep{fortmann2012understanding}.









